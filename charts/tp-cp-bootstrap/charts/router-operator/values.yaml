#
# Copyright Â© 2023 - 2024. Cloud Software Group, Inc.
# This file is subject to the license terms contained
# in the license file that is distributed with this file.
#


## CONTEXT

enableWebHooks: false

# You can use topology spread constraints to control how Pods are spread across your cluster among failure-domains such as regions, zones, nodes,
# and other user-defined topology domains. This can help to achieve high availability as well as efficient resource utilization.
# for more info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: "kubernetes.io/hostname"
  - maxSkew: 1
    topologyKey: "topology.kubernetes.io/zone"

# Resource values for production like setup
resources:
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 1024Mi

# Common labels to add to all router-operator resources. Evaluated as a template.
additionalLabels: {}

image:
  name: infra-router
  tag: 704-distroless
  pullPolicy: IfNotPresent

ports:
  api:
    enabled: true
    containerPort: 88
    servicePort: 88
    protocol: TCP
    targetPort: api
  virtual:
    enabled: true
    containerPort: 100
    servicePort: 100
    protocol: TCP
    targetPort: virtual

# liveness probe configuration
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
livenessProbe:
  httpGet:
    port: 88
    path: /health

# readiness probe configuration
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
readinessProbe:
  httpGet:
    port: 88
    path: /health

service:
  # Enable the creation of a Service.
  enabled: true

  type: ClusterIP
  # type: LoadBalancer
  # loadBalancerIP: 1.2.3.4
  # loadBalancerSourceRanges: []

  # By default, Service of type 'LoadBalancer' will be created setting 'externalTrafficPolicy: Cluster'
  # unless other value is explicitly set.
  # Possible values are Cluster or Local (https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip)
  # externalTrafficPolicy: Cluster

  annotations: {}

  # By default, Service will be created setting 'internalTrafficPolicy: Local' on mode = daemonset
  # unless other value is explicitly set.
  # Setting 'internalTrafficPolicy: Cluster' on a daemonset is not recommended
  # internalTrafficPolicy: Cluster

ingress:
  enabled: false
  annotations: {}
  # ingressClassName: nginx
  # hosts:
  #   - host: router.example.com
  #     paths:
  #       - path: /
  #         pathType: Prefix
  #         port: 100
  # tls:
  #   - secretName: router-tls
  #     hosts:
  #       - router.example.com

  # Additional ingresses - only created if ingress.enabled is true
  # Useful for when differently annotated ingress services are required
  # Each additional ingress needs key "name" set to something unique
  additionalIngresses: []
  # - name: cloudwatch
  #   ingressClassName: nginx
  #   annotations: {}
  #   hosts:
  #     - host: router.example.com
  #       paths:
  #         - path: /
  #           pathType: Prefix
  #           port: 105
  #   tls:
  #     - secretName: router-tls
  #       hosts:
  #         - router.example.com

# no of replicas
replicaCount: "1"

# HPA rules to scale the pod. For more info: https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/
# Scale pods when the cpu and memory usage exceed 70% of the request.
hpa:
  cpu: 70
  mem: 70

# Pod Security Context configuration
# This configuration ensures that the pod is run with non-root privileges for enhanced security.
# The user, group, and filesystem group IDs are all set to 1000.
# The filesystem group change policy is set to "Always", meaning the filesystem group is always set to the fsGroup.
# The seccomp (secure computing mode) profile is set to RuntimeDefault, which means it uses the default profile provided by the runtime.
# The sysctls configuration allows the router to bind to low ports (below 1024) as a non-root user.
# This is achieved by setting the 'net.ipv4.ip_unprivileged_port_start' sysctl to 0.
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  fsGroupChangePolicy: "Always"
  seccompProfile:
    type: RuntimeDefault
  # https://kubernetes.io/docs/concepts/security/pod-security-standards/#baseline
  sysctls:
  - name: "net.ipv4.ip_unprivileged_port_start"
    value: "0"

securityContext:
  # This section of the configuration is for the router.
  # It specifies that privilege escalation is not allowed for security reasons.
  # Additionally, it drops all capabilities, which is a common security practice to minimize potential risks.
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL
        
global:
  tibco:
    # user provided service account.
    serviceAccount: ""
    containerRegistry:
      url: ""
      repository: "tibco-platform-docker-prod"
    # control plane instance Id. Ex: prod, stag, p01, s01. This is to identify multiple cp installation in same cluster.
    # lowercase alphanumeric string of max 5 chars
    controlPlaneInstanceId: ""

    # The fluentbit configuration section.
    # It specifies that the fluentbit should not run as a non-root user and the user ID should be 0 (root).
    # Privilege escalation is not allowed for security reasons.
    # Additionally, it drops all capabilities, which is a common security practice to minimize potential risks.
    # GitHub issue: https://github.com/fluent/fluent-bit/issues/872#issuecomment-827763207, https://github.com/kyma-project/kyma/pull/11657/files
    logging:
      fluentbit:
        enabled: true
        image:
          name: "common-fluentbit"
          registry: ""
          repo: ""
          tag: 4.0.0
          pullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
            memory: 100Mi
          limits:
            cpu: 100m
            memory: 150Mi

  external:
    clusterInfo:
      nodeCIDR: ""
      podCIDR: ""
    dnsDomain: ""