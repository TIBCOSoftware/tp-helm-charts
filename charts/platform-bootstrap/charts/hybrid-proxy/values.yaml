## CONTEXT

# to enable the chart
enabled: true

# to enable or disable webhooks (by default disabled)
enableWebHooks: false

settingsConfigmap:
  - key: "LOG_LEVEL"
    value: "info"

waitForBackendPodToBeReady: true

# You can use topology spread constraints to control how Pods are spread across your cluster among failure-domains such as regions, zones, nodes,
# and other user-defined topology domains. This can help to achieve high availability as well as efficient resource utilization.
# for more info: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/
topologySpreadConstraints:
  - maxSkew: 1
    topologyKey: "kubernetes.io/hostname"
  - maxSkew: 1
    topologyKey: "topology.kubernetes.io/zone"

# Resource values for production like setup
resources:
  requests:
    cpu: 200m
    memory: 256Mi
  limits:
    cpu: 500m
    memory: 1024Mi

# Common labels to add to all hybrid-proxy resources. Evaluated as a template.
additionalLabels: {}

# HPA
hpa:
  cpu: 70
  mem: 70

image:
  name: infra-hybrid-proxy
  tag: 91-distroless
  pullPolicy: IfNotPresent

ports:
  api:
    enabled: true
    serviceEnabled: true
    containerPort: 88
    servicePort: 88
    protocol: TCP
    targetPort: api
  tunnel:
    enabled: true
    serviceEnabled: true
    containerPort: 443
    servicePort: 105
    protocol: TCP
    targetPort: tunnel

# liveness probe configuration
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
livenessProbe:
  httpGet:
    port: 88
    path: /version

# readiness probe configuration
# Ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/
##
readinessProbe:
  httpGet:
    port: 88
    path: /version

service:
  # Enable the creation of a Service.
  enabled: true

  type: ClusterIP
  # type: LoadBalancer
  # loadBalancerIP: 1.2.3.4
  # loadBalancerSourceRanges: []
  # loadBalancerClass: ""

  # You can optionally disable node port allocation for a Service of type: LoadBalancer, by setting the field spec.allocateLoadBalancerNodePorts to false.
  # This should only be used for load balancer implementations that route traffic directly to pods as opposed to using node ports.
  # By default, spec.allocateLoadBalancerNodePorts is true and type LoadBalancer Services will continue to allocate node ports.
  # allocateLoadBalancerNodePorts: false

  # By default, Service of type 'LoadBalancer' will be created setting 'externalTrafficPolicy: Cluster'
  # unless other value is explicitly set.
  # Possible values are Cluster or Local (https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip)
  # externalTrafficPolicy: Cluster

  annotations: {}

  # By default, Service will be created setting 'internalTrafficPolicy: Local' on mode = daemonset
  # unless other value is explicitly set.
  # Setting 'internalTrafficPolicy: Cluster' on a daemonset is not recommended
  # internalTrafficPolicy: Cluster

ingress:
  enabled: false
  annotations: {}
  # ingressClassName: nginx
  # hosts:
  #   - host: hybrid-proxy.example.com
  #     paths:
  #       - path: /
  #         pathType: Prefix
  #         port: 105
  # tls:
  #   - secretName: hybrid-proxy-tls
  #     hosts:
  #       - hybrid-proxy.example.com

  # Additional ingresses - only created if ingress.enabled is true
  # Useful for when differently annotated ingress services are required
  # Each additional ingress needs key "name" set to something unique
  additionalIngresses: []
  # - name: cloudwatch
  #   ingressClassName: nginx
  #   annotations: {}
  #   hosts:
  #     - host: hybrid-proxy.example.com
  #       paths:
  #         - path: /
  #           pathType: Prefix
  #           port: 105
  #   tls:
  #     - secretName: hybrid-proxy-tls
  #       hosts:
  #         - hybrid-proxy.example.com

# no of replicas
replicaCount: "1"

# Pod Security Context configuration
# This configuration ensures that the pod is run with non-root privileges for enhanced security.
# The user, group, and filesystem group IDs are all set to 1000.
# The filesystem group change policy is set to "Always", meaning the filesystem group is always set to the fsGroup.
# The seccomp (secure computing mode) profile is set to RuntimeDefault, which means it uses the default profile provided by the runtime.
# The sysctls configuration allows the platform hybrid proxy to bind to low ports (below 1024) as a non-root user.
# This is achieved by setting the 'net.ipv4.ip_unprivileged_port_start' sysctl to 0.
podSecurityContext:
  runAsNonRoot: true
  runAsUser: 1000
  runAsGroup: 1000
  fsGroup: 1000
  fsGroupChangePolicy: "Always"
  seccompProfile:
    type: RuntimeDefault
  # https://kubernetes.io/docs/concepts/security/pod-security-standards/#baseline
  sysctls:
  - name: "net.ipv4.ip_unprivileged_port_start"
    value: "0"

securityContext:
  # This section of the configuration is for the platform hybrid proxy.
  # It specifies that privilege escalation is not allowed for security reasons.
  # Additionally, it drops all capabilities, which is a common security practice to minimize potential risks.
  allowPrivilegeEscalation: false
  readOnlyRootFilesystem: true
  capabilities:
    drop:
      - ALL
        
global:
  tibco:
    serviceAccount: ""
    containerRegistry:
      url: ""
      repository: "tibco-platform-docker-prod"      
    # control plane instance Id. Ex: prod, stag, p01, s01. This is to identify multiple cp installation in same cluster.
    # lowercase alphanumeric string of max 5 chars
    controlPlaneInstanceId: ""

    # The fluentbit configuration section.
    # It specifies that the fluentbit should not run as a non-root user and the user ID should be 0 (root).
    # Privilege escalation is not allowed for security reasons.
    # Additionally, it drops all capabilities, which is a common security practice to minimize potential risks.
    logging:
      fluentbit:
        enabled: true
        image:
          name: "common-fluentbit"
          registry: ""
          repo: ""
          tag: 4.0.8
          pullPolicy: IfNotPresent
        resources:
          requests:
            cpu: 50m
            memory: 100Mi
          limits:
            cpu: 100m
            memory: 150Mi

  external:
    dnsTunnelDomain: ""
